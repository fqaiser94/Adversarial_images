{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fqaiser94/.local/lib/python3.5/site-packages/matplotlib/__init__.py:1405: UserWarning: \nThis call to matplotlib.use() has no effect because the backend has already\nbeen chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\nor matplotlib.backends is imported for the first time.\n\n  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# supress tensorflow logging other than errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys, Estimator\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# first we have to get our data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n '__class__',\n '__contains__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getnewargs__',\n '__gt__',\n '__hash__',\n '__init__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__rmul__',\n '__setattr__',\n '__sizeof__',\n '__slots__',\n '__str__',\n '__subclasshook__',\n '_asdict',\n '_fields',\n '_make',\n '_replace',\n '_source',\n 'count',\n 'index',\n 'test',\n 'train',\n 'validation']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_epochs_completed',\n '_images',\n '_index_in_epoch',\n '_labels',\n '_num_examples',\n 'epochs_completed',\n 'images',\n 'labels',\n 'next_batch',\n 'num_examples']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to understand what the images object is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images is a tensor (i.e an n-dimensional array). The tensor has a shape as follows.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension indicate the number of images while the second dimension indicates the  number of pixels in each image.  \n",
    "\n",
    "Each entry in the tensor is the pixel intensity between 0 and 1, for a particular pixel in a particular image.  \n",
    "\n",
    "Now let's look at the labels object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another tensor, no surpise. Let's have a look at its dimensions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the first dimension (i.e. each row) corresponds to the index of an image. The second dimension indicates the that we have 10 data points (i.e. columns) for each image. These 10 data points are essentially a categorical encoding of the class (or label) of each image (0-9). \n",
    "\n",
    "Let's see if we can visualize one of these images and its corresponding label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(tensor, index):\n",
    "    \n",
    "    image = (tensor\n",
    "             .images[index]\n",
    "             .reshape([50,50])\n",
    "             )\n",
    "    \n",
    "    label = (tensor\n",
    "             .labels[index]\n",
    "             .tolist()\n",
    "             .index(1)\n",
    "             )\n",
    "    \n",
    "    print('Showing an image of the number %s' % label)\n",
    "    \n",
    "    plt.imshow(image, \n",
    "               cmap = plt.get_cmap('gray_r'))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.savefig('fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing an image of the number 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8kRfiBpAg/kBThB5L6f/pagUHWFTfPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ea51f1550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ea52144e0>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_digit(tensor=mnist.train, \n",
    "              index=np.random.randint(low=0,\n",
    "                                      high=mnist.train.num_examples)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, so we have some intuition for our data now.  \n",
    "\n",
    "As you can see, the images aren't \"perfect\" which makes sense since these are supposed to be hand-drawn digits.  \n",
    "\n",
    "Now, let's try building a deep learning model to predict the class of an image.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start building the computation graph \n",
    "# by creating nodes for the input images and \n",
    "# target output classes.\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# The input images x will consist of a 2d tensor \n",
    "# of floating point numbers. \n",
    "# Here we assign it a shape of [None, 784], \n",
    "# where 784 is the dimensionality of \n",
    "# a single flattened 28 by 28 pixel MNIST image, \n",
    "# and None indicates that the first dimension, \n",
    "# corresponding to the batch size, \n",
    "# can be of any size. \n",
    "# The target output classes y_ will also \n",
    "# consist of a 2d tensor, where each row is a \n",
    "# one-hot 10-dimensional vector indicating which \n",
    "# digit class (zero through nine) the corresponding \n",
    "# MNIST image belongs to.\n",
    "\n",
    "# The shape argument to placeholder is optional, \n",
    "# but it allows TensorFlow to automatically catch bugs \n",
    "# stemming from inconsistent tensor shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define the weights W and biases b for our model.\n",
    "# We could imagine treating these like additional inputs,\n",
    "# but TensorFlow has an even better way to handle them: \n",
    "# Variable. \n",
    "# A Variable is a value that lives in \n",
    "# TensorFlow's computation graph. \n",
    "# It can be used and even modified by the computation. \n",
    "# In machine learning applications, \n",
    "# one generally has the model parameters be Variables.\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# We pass the initial value for each parameter in the \n",
    "# call to tf.Variable. \n",
    "# In this case, we initialize both W and b as tensors \n",
    "# full of zeros. W is a 784x10 matrix (because we \n",
    "# have 784 input features and 10 outputs) and b \n",
    "# is a 10-dimensional vector (because we have 10 \n",
    "# classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Variables can be used within a session, \n",
    "# they must be initialized using that session. \n",
    "# This step takes the initial values \n",
    "# (in this case tensors full of zeros) that have \n",
    "# already been specified, and assigns them to each \n",
    "# Variable. This can be done for all Variables at once:\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now implement our regression model. \n",
    "# It only takes one line! \n",
    "# We multiply the vectorized input images x by \n",
    "# the weight matrix W, add the bias b.\n",
    "\n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify a loss function just as easily. \n",
    "# Loss indicates how bad the model's prediction was \n",
    "# on a single example; we try to minimize that while \n",
    "# training across all the examples. Here, our loss \n",
    "# function is the cross-entropy between the target \n",
    "# and the softmax activation function applied to \n",
    "# the model's prediction. As in the beginners tutorial, \n",
    "# we use the stable formulation:\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# Note that tf.nn.softmax_cross_entropy_with_logits \n",
    "# internally applies the softmax on the model's \n",
    "# unnormalized model prediction and sums across all \n",
    "# classes, and tf.reduce_mean takes the average over \n",
    "# these sums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built a model, let's train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have defined our model and training loss \n",
    "# function, it is straightforward to train using \n",
    "# TensorFlow. Because TensorFlow knows the entire \n",
    "# computation graph, it can use automatic differentiation \n",
    "# to find the gradients of the loss with respect to each \n",
    "# of the variables. TensorFlow has a variety of \n",
    "# built-in optimization algorithms. For this example, \n",
    "# we will use steepest gradient descent, with a step \n",
    "# length of 0.5, to descend the cross entropy.\n",
    "\n",
    "train_step = (tf\n",
    "              .train\n",
    "              .GradientDescentOptimizer(0.5)\n",
    "              .minimize(cross_entropy)\n",
    "              )\n",
    "\n",
    "# What TensorFlow actually did in that single line was \n",
    "# to add new operations to the computation graph. These \n",
    "# operations included ones to compute gradients, compute \n",
    "# parameter update steps, and apply update steps to the \n",
    "# parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned operation train_step, when run, \n",
    "# will apply the gradient descent updates to the \n",
    "# parameters. Training the model can therefore be \n",
    "# accomplished by repeatedly running train_step.\n",
    "\n",
    "for _ in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "  \n",
    "# We load 100 training examples in each training \n",
    "# iteration. We then run the train_step operation, \n",
    "# using feed_dict to replace the placeholder tensors \n",
    "# x and y_ with the training examples. Note that you \n",
    "# can replace any tensor in your computation graph \n",
    "# using feed_dict -- it's not restricted to just \n",
    "# placeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# First we'll figure out where we predicted the correct \n",
    "# label. tf.argmax is an extremely useful function which \n",
    "# gives you the index of the highest entry in a tensor \n",
    "# along some axis. For example, tf.argmax(y,1) is the \n",
    "# label our model thinks is most likely for each input, \n",
    "# while tf.argmax(y_,1) is the true label. We can use \n",
    "# tf.equal to check if our prediction matches the truth.\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), \n",
    "                              tf.argmax(y,1)\n",
    "                              )\n",
    "\n",
    "# That gives us a list of booleans. To determine what \n",
    "# fraction are correct, we cast to floating point \n",
    "# numbers and then take the mean. For example, \n",
    "# [True, False, True, True] would become [1,0,1,1] \n",
    "# which would become 0.75.\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \n",
    "                                  tf.float32))\n",
    "\n",
    "# Finally, we can evaluate our accuracy on the test \n",
    "# data. This should be about 92% correct.\n",
    "\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, \n",
    "                               y_: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing github integration. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
