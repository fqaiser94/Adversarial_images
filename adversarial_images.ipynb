{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fqaiser94/.local/lib/python3.5/site-packages/matplotlib/__init__.py:1405: UserWarning: \nThis call to matplotlib.use() has no effect because the backend has already\nbeen chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\nor matplotlib.backends is imported for the first time.\n\n  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# supress tensorflow logging other than errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys, Estimator\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# first we have to get our data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n '__class__',\n '__contains__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getnewargs__',\n '__gt__',\n '__hash__',\n '__init__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__rmul__',\n '__setattr__',\n '__sizeof__',\n '__slots__',\n '__str__',\n '__subclasshook__',\n '_asdict',\n '_fields',\n '_make',\n '_replace',\n '_source',\n 'count',\n 'index',\n 'test',\n 'train',\n 'validation']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_epochs_completed',\n '_images',\n '_index_in_epoch',\n '_labels',\n '_num_examples',\n 'epochs_completed',\n 'images',\n 'labels',\n 'next_batch',\n 'num_examples']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to understand what the images object is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images is a tensor (i.e an n-dimensional array). The tensor has a shape as follows.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension indicate the number of images while the second dimension indicates the  number of pixels in each image.  \n",
    "\n",
    "Each entry in the tensor is the pixel intensity between 0 and 1, for a particular pixel in a particular image.  \n",
    "\n",
    "Now let's look at the labels object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another tensor, no surpise. Let's have a look at its dimensions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the first dimension (i.e. each row) corresponds to the index of an image. The second dimension indicates the that we have 10 data points (i.e. columns) for each image. These 10 data points are essentially a categorical encoding of the class (or label) of each image (0-9). \n",
    "\n",
    "Let's see if we can visualize one of these images and its corresponding label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(tensor, index):\n",
    "    \n",
    "    image = (tensor\n",
    "             .images[index]\n",
    "             .reshape([50,50])\n",
    "             )\n",
    "    \n",
    "    label = (tensor\n",
    "             .labels[index]\n",
    "             .tolist()\n",
    "             .index(1)\n",
    "             )\n",
    "    \n",
    "    print('Showing an image of the number %s' % label)\n",
    "    \n",
    "    plt.imshow(image, \n",
    "               cmap = plt.get_cmap('gray_r'))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.savefig('fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing an image of the number 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8kRfiBpAg/kBThB5L6f/pagUHWFTfPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ea51f1550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ea52144e0>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_digit(tensor=mnist.train, \n",
    "              index=np.random.randint(low=0,\n",
    "                                      high=mnist.train.num_examples)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, so we have some intuition for our data now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
